

# ğŸŒ **SynthÃ¨se comparative â€” VMware ESXi, Proxmox VE et Incus**
*Comparaison technique des trois solutions Ã©tudiÃ©es dans le cadre du projet.*

Lâ€™infrastructure initialement envisagÃ©e reposait sur **VMware ESXi**, hyperviseur rÃ©putÃ© pour sa **stabilitÃ©** et son **adoption dans le monde professionnel**.  
Au cours du projet, deux solutions alternatives ont Ã©tÃ© Ã©tudiÃ©es et dÃ©ployÃ©es : **Proxmox VE**, environnement dâ€™hypervision libre intÃ©grant **virtualisation complÃ¨te**, **conteneurs** et **capacitÃ©s de clustering avancÃ©es**, et **Incus**, plateforme moderne de **conteneurisation systÃ¨me** dÃ©rivÃ©e de LXD.

Cette synthÃ¨se analyse les **fonctionnements**, **forces**, **limites** et **domaines dâ€™usage** de ces trois technologies, afin de comprendre ce que chacune peut apporter â€” ou non â€” Ã  une architecture virtuelle.

---

## **1. VMware ESXi â€” Un hyperviseur professionnel robuste et Ã©prouvÃ©**

VMware ESXi repose sur une architecture **bareâ€‘metal**, oÃ¹ lâ€™hyperviseur est installÃ© directement sur le serveur **sans systÃ¨me dâ€™exploitation intermÃ©diaire**.  
Son fonctionnement repose exclusivement sur la **virtualisation complÃ¨te** via le moteur **VMkernel**, reconnu pour sa **stabilitÃ©** et son **efficacitÃ©**.

ESXi se distingue par une excellente **gestion des ressources**, une grande **fiabilitÃ©**, et une intÃ©gration serrÃ©e avec lâ€™Ã©cosystÃ¨me VMware (**vCenter**, **vMotion**, **VSAN**, **HA**â€¦).  
Cependant, bon nombre de fonctionnalitÃ©s avancÃ©es â€” telles que la **haute disponibilitÃ©**, le **clustering**, ou la **migration Ã  chaud** â€” nÃ©cessitent **vCenter**, une solution **payante**.

La dÃ©pendance aux **licences** et lâ€™Ã©cosystÃ¨me **propriÃ©taire** limitent la flexibilitÃ© et augmentent le coÃ»t dâ€™adoption, en particulier pour des environnements Ã©ducatifs ou expÃ©rimentaux.

**ESXi offre donc une plateforme extrÃªmement solide, mais parfois rigide et coÃ»teuse.**

---

## **2. Proxmox VE â€” Une alternative complÃ¨te, ouverte et polyvalente**

Proxmox VE combine dans un mÃªme environnement :

- un hyperviseur **KVM** pour la virtualisation complÃ¨te,  
- **LXC** pour la virtualisation lÃ©gÃ¨re,  
- la gestion native du stockage **ZFS**,  
- un **clustering intÃ©grÃ©**,  
- lâ€™utilisation directe de **Ceph** pour le stockage distribuÃ©.

Son fonctionnement repose entiÃ¨rement sur des technologies **openâ€‘source** Ã©prouvÃ©es.  
Contrairement Ã  ESXi, Proxmox ne nÃ©cessite **aucun composant propriÃ©taire** pour activer le **clustering**, la **migration de VM** ou la **haute disponibilitÃ©**.

L'interface web est **moderne**, **centralisÃ©e** et **intuitive**, ce qui facilite la gestion de plusieurs nÅ“uds.  
La flexibilitÃ© de Proxmox est un atout : stockage hybride, intÃ©gration rÃ©seau avancÃ©e, gestion fine des conteneurs comme des machines virtuelles.

Sa seule limite rÃ©elle rÃ©side dans une **consommation de ressources plus Ã©levÃ©e** que celle dâ€™un hyperviseur spÃ©cialisÃ©, ainsi quâ€™une architecture parfois plus **complexe** Ã  maÃ®triser lorsque lâ€™on combine **cluster**, **Ceph** et **ZFS**.

---

## **3. Incus â€” Conteneurisation systÃ¨me performante et flexible**

Incus est un systÃ¨me de **system containers**, orientÃ© vers la **virtualisation lÃ©gÃ¨re**.  
Contrairement Ã  ESXi et Proxmox, Incus ne propose **pas de virtualisation complÃ¨te** : les conteneurs partagent **le noyau de lâ€™hÃ´te**.

Cette approche permet une **efficacitÃ© exceptionnelle** :  
- consommation **minimale** de ressources,  
- dÃ©marrage **instantanÃ©**,  
- dÃ©ploiement **rapide en sÃ©rie**,  
- snapshots **quasi immÃ©diats**.

Incus propose Ã©galement des fonctionnalitÃ©s avancÃ©es comme la **gestion de profils**, la **configuration rÃ©seau intÃ©grÃ©e**, les **images cloudâ€‘init**, et le **clustering multiâ€‘nÅ“uds**.

En revanche, Incus ne peut pas exÃ©cuter des systÃ¨mes nÃ©cessitant **leur propre kernel** (Windows, appliances virtuelles, etc.).  
Il ne remplace donc pas un **hyperviseur classique**.

Son usage est idÃ©al pour des environnements **DevOps**, des environnements de **test**, ou des dÃ©ploiements massifs de conteneurs systÃ¨me, mais pas pour des workloads nÃ©cessitant une **isolation matÃ©rielle complÃ¨te**.


## Comparatif gÃ©nÃ©ral des fonctionnalitÃ©s

| CritÃ¨re                | **VMware ESXi**                                   | **Proxmox VE**                   | **Incus**                        |
| ---------------------- | ------------------------------------------------- | -------------------------------- | -------------------------------- |
| Type de virtualisation | **Virtualisation complÃ¨te**                       | **KVM (VM) + LXC (conteneurs)**  | **Conteneurs systÃ¨me**           |
| Licence                | PropriÃ©taire (payant pour les fonctions avancÃ©es) | **Openâ€‘source**                  | **Openâ€‘source**                  |
| Clustering             | âœ” Avec vCenter (payant)                           | **âœ” IntÃ©grÃ© nativement**         | âœ” Clustering conteneurs          |
| Migration Ã  chaud      | âœ” vMotion (payant)                                | **âœ” Native, gratuite**           | N/A (pas de VM)                  |
| Stockage distribuÃ©     | âœ” VSAN (licence)                                  | **âœ” Ceph intÃ©grÃ©**               | Support externe possible         |
| Haute disponibilitÃ©    | âœ” Avec vCenter                                    | **âœ” Proxmox HA (Ceph)**          | LimitÃ© aux conteneurs            |
| Performances           | Excellentes                                       | TrÃ¨s bonnes                      | **Exceptionnelles (conteneurs)** |
| FlexibilitÃ©            | Moyenne (Ã©cosystÃ¨me fermÃ©)                        | **TrÃ¨s Ã©levÃ©e**                  | TrÃ¨s Ã©levÃ©e                      |
| Support OS invitÃ©s     | Tous OS                                           | Tous OS                          | Linux uniquement (mÃªme kernel)   |
| IdÃ©al pour             | Production pro propriÃ©taire                       | **Infra pro/Ã©ducative complÃ¨te** | DevOps, labs, conteneurs         |


---

















# Serveur Incus - Document Technique

Projet de virtualisation â€” SAE / Infrastructure rÃ©seau

# 1. Mise en service physique du serveur

Pour initialiser le serveur, jâ€™ai procÃ©dÃ© Ã  une prise en main locale. La machine Ã©tait Ã©quipÃ©e dâ€™un module ILO (Integrated Lights-Out) permettant une administration Ã  distance, mais les identifiants avaient Ã©tÃ© perdus.

Jâ€™ai donc connectÃ© localement :

un Ã©cran,

un clavier,

un cÃ¢ble rÃ©seau sur le port ILO.

Cela mâ€™a permis dâ€™accÃ©der Ã  lâ€™interface BIOS du serveur, rÃ©initialiser les identifiants ILO, et retrouver un contrÃ´le complet de la machine.

## RÃ©initialisation et accÃ¨s BIOS

Jâ€™ai restaurÃ© le mot de passe et le nom dâ€™utilisateur ILO directement depuis le BIOS, permettant la reprise complÃ¨te de lâ€™administration du serveur.

# 2. IntÃ©gration rÃ©seau ILO

Le serveur devait Ãªtre intÃ©grÃ© dans notre rÃ©seau pÃ©dagogique, dÃ©fini sur la plage :

10.202.0.0/16


Le premier serveur Proxmox avait dÃ©jÃ  pour adresse :

10.202.4.1/16


Jâ€™ai attribuÃ© au module ILO une adresse disponible :

10.202.4.2/16


Cette configuration permettait une administration distante via navigateur :

https://10.202.4.2


ğŸ“· Capture Ã  insÃ©rer : Administration ILO affichant lâ€™adresse 10.202.4.2

# 3. Nettoyage du stockage (RAID matÃ©riel)

Avant dâ€™installer un systÃ¨me dâ€™exploitation propre, le serveur contenait plusieurs volumes RAID matÃ©riels historiques.
Je les ai supprimÃ©s via lâ€™outil RAID du BIOS afin de repartir sur un stockage vierge.

## Objectifs

Ã©viter les conflits lors de lâ€™installation,

Ã©liminer dâ€™anciennes signatures de partitions,

garantir un systÃ¨me stable et propre.

ğŸ“· Capture Ã  insÃ©rer : RAID avant / aprÃ¨s suppression

# 4. Installation de Ubuntu Server

Jâ€™ai tÃ©lÃ©chargÃ© lâ€™image ISO Ubuntu Server sur mon poste, puis je lâ€™ai montÃ©e virtuellement via lâ€™interface ILO.
Le serveur a Ã©tÃ© configurÃ© pour booter sur lâ€™ISO et lancer lâ€™installation.

Le systÃ¨me Ubuntu a Ã©tÃ© installÃ© sur un seul disque, avec la structure recommandÃ©e :

Partition EFI
Partition /


ğŸ“· Capture Ã  insÃ©rer : ILO affichant ISO montÃ©

# 5. Configuration rÃ©seau du systÃ¨me Ubuntu

Une fois lâ€™installation terminÃ©e, jâ€™ai configurÃ© la carte rÃ©seau principale en adressage statique.

Adresse IP   : 10.202.4.69/16
Passerelle   : 10.202.4.1
DNS          : 1.1.1.1 ou 8.8.8.8


Cette adresse est distincte de lâ€™adresse ILO, car un contrÃ´le physique (ILO) ne doit jamais partager la mÃªme identitÃ© rÃ©seau que lâ€™OS principal.

Une fois la configuration appliquÃ©e, on pouvait accÃ©der au serveur en SSH :

ssh titouan@10.202.4.69


ğŸ“· Capture Ã  insÃ©rer : ip addr ou Netplan confirmant lâ€™IP 10.202.4.69

6. Installation du dÃ©mon Incus

Incus est un dÃ©mon de virtualisation basÃ© sur la technologie LXC/LXD. Il permet dâ€™hÃ©berger :

des conteneurs Linux,

des machines virtuelles lÃ©gÃ¨res,

des environnements de test,

des snapshots et migrations.

Lâ€™installation demande la configuration du dÃ©pÃ´t Zabbly, car Incus nâ€™est pas prÃ©sent dans les dÃ©pÃ´ts Ubuntu officiels.

## ProcÃ©dure technique simplifiÃ©e
sudo apt update
sudo apt install incus
sudo incus admin init


ğŸ“· Capture Ã  insÃ©rer : Installation Incus rÃ©ussie dans le terminal

## Initialisation dâ€™Incus

La commande suivante configure automatiquement :

le stockage,

le rÃ©seau virtuel,

lâ€™accÃ¨s distant,

et lâ€™activation du dÃ©mon.

sudo incus admin init


Incus devient ensuite pleinement opÃ©rationnel.

7. DÃ©ploiement de lâ€™interface Incus UI (HTTPS)

MÃªme si Incus est administrable entiÃ¨rement en ligne de commande, une interface web permet de :

visualiser les conteneurs,

gÃ©rer les ressources,

lancer des commandes,

crÃ©er des snapshots,

surveiller lâ€™activitÃ© rÃ©seau,

dÃ©ployer des VM plus rapidement.

Jâ€™ai installÃ© Incus UI, qui expose une interface HTTPS sur le port :

8443

## SÃ©curisation HTTPS par certificats

Lâ€™accÃ¨s web nÃ©cessite la mise en place de certificats SSL.

### Sur le serveur (Incus)

gÃ©nÃ©ration dâ€™un certificat .crt

ajout du certificat Ã  Incus

activation de lâ€™accÃ¨s distant

### Sur le navigateur (Chrome)

importation dâ€™un certificat .pfx

validation de la confiance locale

## Pare-feu Ubuntu (UFW)

Ouverture du port sÃ©curisÃ© :

sudo ufw allow 8443


ğŸ“· Capture Ã  insÃ©rer : ufw status montrant le port 8443 ouvert

## AccÃ¨s Ã  Incus UI

Une fois les certificats installÃ©s :

https://10.202.4.69:8443/ui


ğŸ“· Capture Ã  insÃ©rer : Incus UI fonctionnel dans le navigateur

8. CrÃ©ation dâ€™instances (conteneurs et VM)

Depuis Incus UI, jâ€™ai pu dÃ©ployer :

2 conteneurs AlmaLinux

1 conteneur Devuan

1 machine virtuelle Linux Mint

Ces instances ont Ã©tÃ© crÃ©Ã©es et administrÃ©es directement depuis le navigateur, avec :

configuration rÃ©seau,

monitoring,

consoles interactives,

snapshots,

gestion des ressources.

ğŸ“· Capture Ã  insÃ©rer : liste des instances dans Incus UI

9. SchÃ©ma dâ€™architecture globale

Voici une reprÃ©sentation simplifiÃ©e de lâ€™infrastructure :

                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚           Internet           â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                         LAN 10.202.4.0/16
                                       â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚             SWITCH RÃ©seau           â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚       Serveur #1          â”‚
          â”‚         Proxmox           â”‚
          â”‚       10.202.4.1          â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚       Serveur #2          â”‚
          â”‚  Ubuntu + Incus + UI      â”‚
          â”‚       10.202.4.69         â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             Instances Incus                  â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚  â”‚ AlmaLinux   â”‚ Devuan      â”‚ Linux Mint   â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

10. Conclusion professionnelle

Ce projet mâ€™a permis de dÃ©ployer une plateforme complÃ¨te de virtualisation basÃ©e sur Incus, depuis un serveur physique vierge, jusquâ€™Ã  une administration graphique sÃ©curisÃ©e en HTTPS.

Jâ€™ai manipulÃ© :

administration matÃ©rielle via ILO,

configuration rÃ©seau statique,

suppression de RAID,

installation systÃ¨me Ubuntu,

installation du dÃ©mon Incus,

configuration de certificats SSL,

mise en place du pare-feu,

dÃ©ploiement dâ€™instances conteneurs et VM depuis une interface web.

Cette infrastructure est aujourdâ€™hui stable, moderne, automatisable, et adaptÃ©e Ã  des usages pÃ©dagogiques, exploratoires ou applicatifs.
